#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–¹æ³• Cï¼šå•æ¬¡è¿è¡Œæ‰¹é‡ç”Ÿæˆï¼ˆBatchï¼‰+ æ•è·å¹¶ä¿å­˜ DiT è¾“å…¥/è¾“å‡º latentï¼ˆDiffusers / Wan2.1 T2V-1.3Bï¼‰

è¾“å‡ºç»“æ„ï¼š
  wan_batch_runs/session-YYYYMMDD-HHMMSS/
    â”œâ”€â”€ batched/
    â”‚   â”œâ”€â”€ dit_inputs_batched.pt    # list[tuple(...)]ï¼Œå…¶ä¸­å¼ é‡çš„ batch ç»´åº¦=B
    â”‚   â””â”€â”€ dit_outputs_batched.pt   # list[tensor]ï¼Œshape=(B, C, T, H, W)
    â””â”€â”€ sample00/
        â”œâ”€â”€ output.mp4
        â”œâ”€â”€ dit_inputs.pt            # å·²æŒ‰æ ·æœ¬åˆ‡åˆ†åçš„ list[tuple(...)]ï¼ˆå„å¼ é‡ batch ç»´å·²åˆ‡æˆå•æ ·æœ¬ï¼‰
        â”œâ”€â”€ dit_outputs.pt           # list[tensor]ï¼ˆå„å¼ é‡å»æ‰ batch ç»´ -> (1, C, T, H, W) æˆ– (C,T,H,W)ï¼‰
        â”œâ”€â”€ metadata.json
        â””â”€â”€ step_map.json
       sample01/...
       ...

æ³¨æ„ï¼š
- å¯ç”¨ CFG (guidance_scale>1) æ—¶ï¼Œæ¯æ­¥æœ‰ 2 æ¬¡ DiT è°ƒç”¨ï¼›è‹¥ num_inference_steps=30ï¼Œåˆ™æ€» calls â‰ˆ 60ï¼ˆæ¯ä¸ªè°ƒç”¨è¿”å›ä¸€ä¸ª (B,C,T,H,W) çš„è¾“å‡ºï¼‰ã€‚
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path

os.environ.setdefault("XFORMERS_DISABLED", "1")  # é¿å… xformers/flash-attn å¯¼å…¥å†²çª

def parse_args():
    p = argparse.ArgumentParser(description="Wan2.1 batch generation with DiT latent capture")
    # æ¨¡å‹
    p.add_argument("--model_id", default="Wan-AI/Wan2.1-T2V-1.3B-Diffusers")
    p.add_argument("--local_dir", default="./Wan2.1-T2V-1.3B-Diffusers")
    # å­˜å‚¨
    p.add_argument("--save_root", default="./wan_batch_runs")
    # è§†é¢‘è®¾ç½®
    p.add_argument("--width", type=int, default=832)
    p.add_argument("--height", type=int, default=480)
    p.add_argument("--num_frames", type=int, default=81)
    p.add_argument("--fps", type=int, default=15)
    # é‡‡æ ·ä¸ CFG
    p.add_argument("--guidance_scale", type=float, default=5.5)
    p.add_argument("--steps", type=int, default=30)
    # æç¤ºè¯ï¼šäºŒé€‰ä¸€
    p.add_argument("--prompt", default="A cat walks on the grass, realistic",
                   help="å•ä¸ªæç¤ºè¯ï¼Œè‹¥ä¸ --batch ä¸€èµ·ä½¿ç”¨å°†è¢«å¤åˆ¶ batch æ¬¡")
    p.add_argument("--prompts", default=None,
                   help="ç”¨ '||' åˆ†éš”çš„å¤šä¸ªæç¤ºè¯ï¼Œä¾‹å¦‚ï¼š'cat on grass||a dog running'")
    p.add_argument("--negative_prompt", default=("Bright tones, overexposed, static, blurred details, subtitles, "
                                                 "style, works, paintings, images, static, overall gray, worst quality, "
                                                 "low quality, JPEG compression residue, ugly, incomplete, extra fingers, "
                                                 "poorly drawn hands, poorly drawn faces, deformed, disfigured, "
                                                 "misshapen limbs, fused fingers, still picture, messy background, "
                                                 "three legs, many people in the background, walking backwards"))
    # æ‰¹é‡å¤§å°ï¼ˆå½“æ²¡æä¾› --prompts æ—¶ç”Ÿæ•ˆï¼‰
    p.add_argument("--batch", type=int, default=4, help="ä¸€æ¬¡ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ï¼ˆä¸ prompts æ•°é‡ä¸€è‡´ï¼‰")
    # éšæœºç§å­ï¼ˆå¯ç»™æ¯ä¸ªæ ·æœ¬ä¸€ä¸ªï¼›é•¿åº¦éœ€= batchï¼›è‹¥ä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ base_seed+iï¼‰
    p.add_argument("--seeds", nargs="+", type=int, default=None)
    p.add_argument("--base_seed", type=int, default=1000)
    # è®¾å¤‡/å†…å­˜
    p.add_argument("--device", default="cuda", choices=["cuda", "cpu"])
    p.add_argument("--offload", action="store_true", help="å¯ç”¨ CPU-Offload ä»¥çœæ˜¾å­˜")
    p.add_argument("--t5_cpu", action="store_true", help="æŠŠ T5 æ–‡æœ¬ç¼–ç å™¨æ”¾åˆ° CPU")
    return p.parse_args()

def ensure_model(local_dir_str, repo_id):
    local_dir = Path(local_dir_str).expanduser().resolve()
    if not local_dir.exists() or not any(local_dir.iterdir()):
        print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½æ¨¡å‹åˆ°ï¼š{local_dir}")
        from huggingface_hub import snapshot_download
        snapshot_download(repo_id=repo_id, local_dir=str(local_dir), local_dir_use_symlinks=False)
    else:
        print(f"âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç›®å½•ï¼š{local_dir}")
    return local_dir

def to_cpu_detached(obj):
    import torch
    if isinstance(obj, torch.Tensor):
        return obj.detach().to("cpu")
    elif isinstance(obj, (list, tuple)):
        return type(obj)(to_cpu_detached(x) for x in obj)
    elif isinstance(obj, dict):
        return {k: to_cpu_detached(v) for k, v in obj.items()}
    else:
        return obj

def split_tensor_first_dim(x, B):
    """æŠŠç¬¬ 0 ç»´æ˜¯ batch çš„å¼ é‡åˆ‡æˆ B ä»½ï¼›å¦åˆ™ä¿æŒä¸å˜ã€‚"""
    import torch
    if not isinstance(x, torch.Tensor):
        return [x] * B
    if x.dim() >= 1 and x.size(0) == B:
        return [x[i:i+1].contiguous() for i in range(B)]  # ä¿ç•™ batch ç»´ä¸º 1ï¼Œä¾¿äºä¸€è‡´æ€§
    else:
        # è‹¥ä¸æ˜¯æŒ‰ batch å †å çš„å¼ é‡ï¼ˆä¾‹å¦‚å¸¸é‡ã€æ ‡é‡ï¼‰ï¼Œå¤åˆ¶å¼•ç”¨
        return [x] * B

def split_args_by_batch(args_tuple, B):
    """
    å°†ä¸€æ¬¡ call çš„ inputsï¼ˆtupleï¼‰æŒ‰ batch åˆ‡åˆ†æˆ B ä»½ï¼Œè¿”å› list[tuple(...)]ã€‚
    å¯¹ tuple ä¸­æ¯ä¸ªå¼ é‡ï¼Œè‹¥ç¬¬ 0 ç»´æ˜¯ Bï¼Œåˆ™æ²¿ç¬¬ 0 ç»´åˆ‡åˆ†ï¼›å¦åˆ™åŸæ ·å¤åˆ¶ã€‚
    """
    per_sample = [list() for _ in range(B)]
    for item in args_tuple:
        parts = split_tensor_first_dim(item, B)
        for i in range(B):
            per_sample[i].append(parts[i])
    return [tuple(x) for x in per_sample]

def main():
    args = parse_args()
    import torch
    from diffusers import AutoencoderKLWan, WanPipeline
    from diffusers.utils import export_to_video

    # è®¾å¤‡ & dtype
    if args.device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œåˆ‡æ¢åˆ° CPUï¼ˆè¾ƒæ…¢ï¼‰")
        args.device = "cpu"
    if args.device == "cuda":
        dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16
    else:
        dtype = torch.float32

    # prompts è§£æ
    if args.prompts:
        prompts = [p.strip() for p in args.prompts.split("||") if p.strip()]
    else:
        prompts = [args.prompt] * int(args.batch)
    B = len(prompts)
    print(f"ğŸ“¦ Batch size (B) = {B}")

    # seeds
    if args.seeds is None:
        seeds = [int(args.base_seed) + i for i in range(B)]
    else:
        if len(args.seeds) != B:
            raise ValueError(f"--seeds é•¿åº¦({len(args.seeds)})å¿…é¡»ä¸ batch å¤§å°({B})ä¸€è‡´")
        seeds = [int(s) for s in args.seeds]

    # å°ºå¯¸æ ¡éªŒ
    if args.width % 32 != 0 or args.height % 32 != 0:
        raise ValueError("width/height å¿…é¡»æ˜¯ 32 çš„å€æ•°ï¼ˆä¾‹å¦‚ 832x480ï¼‰")

    # æ¨¡å‹
    local_dir = ensure_model(args.local_dir, args.model_id)
    print("ğŸš€ æ­£åœ¨åŠ è½½ç®¡çº¿ â€¦")
    vae = AutoencoderKLWan.from_pretrained(str(local_dir), subfolder="vae",
                                           torch_dtype=(torch.float32 if args.device == "cpu" else torch.float16))
    pipe = WanPipeline.from_pretrained(str(local_dir), vae=vae, torch_dtype=dtype).to(args.device)
    if args.offload:
        try: pipe.enable_sequential_cpu_offload()
        except Exception: pass
        try: pipe.enable_model_cpu_offload()
        except Exception: pass
    if args.t5_cpu:
        try: pipe.text_encoder.to("cpu")
        except Exception: pass

    # ä¿å­˜æ ¹ç›®å½•
    save_root = Path(args.save_root).expanduser().resolve()
    tag = time.strftime("%Y%m%d-%H%M%S")
    session_dir = save_root / f"session-{tag}"
    (session_dir / "batched").mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{session_dir}")

    # æ•è·å®¹å™¨ï¼ˆæ‰¹é‡ï¼‰
    dit_inputs_args_batched = []   # list[tuple(...)]ï¼ˆå„å¼ é‡ shape çš„ç¬¬ 0 ç»´æ˜¯ Bï¼‰
    dit_outputs_batched = []       # list[tensor (B,C,T,H,W)]

    # hooks
    def pre_hook(mod, inputs, kwargs=None):
        dit_inputs_args_batched.append(tuple(to_cpu_detached(inputs)))
    def fwd_hook(mod, inputs, output):
        if isinstance(output, (list, tuple)):
            out = output[0]
        else:
            out = output
        if isinstance(out, torch.Tensor):
            dit_outputs_batched.append(out.detach().to("cpu"))
        else:
            dit_outputs_batched.append(torch.tensor(0))

    # æ³¨å†Œ hooksï¼ˆä¼˜å…ˆ with_kwargsï¼‰
    try:
        pre_h = pipe.transformer.register_forward_pre_hook(pre_hook, with_kwargs=True)
    except TypeError:
        def pre_hook_no_kwargs(mod, inputs):
            pre_hook(mod, inputs, kwargs=None)
        pre_h = pipe.transformer.register_forward_pre_hook(pre_hook_no_kwargs)
    fwd_h = pipe.transformer.register_forward_hook(fwd_hook, with_kwargs=False)

    # ä¸ºæ¯ä¸ªæ ·æœ¬æ„é€ ç‹¬ç«‹ generator åˆ—è¡¨
    gen_device = "cuda" if args.device == "cuda" else "cpu"
    generators = [torch.Generator(device=gen_device).manual_seed(s) for s in seeds]

    print("ğŸ¬ å•æ¬¡æ‰¹é‡ç”Ÿæˆå¹¶æ•è· latent â€¦")
    try:
        with torch.no_grad():
            result = pipe(
                prompt=prompts,                       # ä¼ å…¥åˆ—è¡¨ï¼Œå½¢æˆ batch
                negative_prompt=[args.negative_prompt]*B,
                height=args.height,
                width=args.width,
                num_frames=args.num_frames,
                guidance_scale=args.guidance_scale,
                num_inference_steps=args.steps,
                generator=generators,                 # ä¸ batch å¯¹é½çš„ generator åˆ—è¡¨
            )
    finally:
        try: pre_h.remove()
        except Exception: pass
        try: fwd_h.remove()
        except Exception: pass

    # === ä¿å­˜æ‰¹é‡åŸå§‹æ•è·ï¼ˆæ–¹ä¾¿åç»­è‡ªå®šä¹‰æ‹†åˆ†/åˆ†æï¼‰ ===
    torch.save(dit_inputs_args_batched, session_dir / "batched" / "dit_inputs_batched.pt")
    torch.save(dit_outputs_batched,    session_dir / "batched" / "dit_outputs_batched.pt")

    # === æ‹†åˆ†å¹¶åˆ†åˆ«ä¸ºæ¯ä¸ªæ ·æœ¬ä¿å­˜ ===
    approx_calls_per_step = 2 if args.guidance_scale and args.guidance_scale > 1.0 else 1
    frames_list = result.frames  # list é•¿åº¦ B
    assert len(frames_list) == B, "è¿”å›çš„ frames æ•°é‡ä¸ batch ä¸åŒ¹é…"

    for i in range(B):
        sample_dir = session_dir / f"sample{i:02d}"
        sample_dir.mkdir(parents=True, exist_ok=True)

        # å¯¼å‡ºè§†é¢‘
        from diffusers.utils import export_to_video
        export_to_video(frames_list[i], str(sample_dir / "output.mp4"), fps=args.fps)

        # æ‹†åˆ† inputsï¼šæ¯æ¬¡ call çš„ tuple -> åˆ‡å‡ºç¬¬ i ä¸ªæ ·æœ¬
        per_sample_inputs = []
        for call_args in dit_inputs_args_batched:
            per_sample_inputs.append(split_args_by_batch(call_args, B)[i])
        torch.save(per_sample_inputs, sample_dir / "dit_inputs.pt")

        # æ‹†åˆ† outputsï¼šæ¯æ¬¡ call çš„å¼ é‡ -> å–ç¬¬ i ä¸ª batch åˆ‡ç‰‡
        per_sample_outputs = []
        for out in dit_outputs_batched:
            if isinstance(out, torch.Tensor) and out.dim() >= 1 and out.size(0) == B:
                per_sample_outputs.append(out[i:i+1].contiguous())  # ä¿ç•™ batch ç»´=1
            else:
                per_sample_outputs.append(out)  # ç½•è§æƒ…å†µï¼šéå¼ é‡æˆ–æ—  batch ç»´
        torch.save(per_sample_outputs, sample_dir / "dit_outputs.pt")

        # å…ƒä¿¡æ¯
        meta = {
            "index": i,
            "seed": seeds[i],
            "prompt": prompts[i],
            "width": args.width, "height": args.height, "num_frames": args.num_frames, "fps": args.fps,
            "guidance_scale": args.guidance_scale, "num_inference_steps": args.steps,
            "dtype": str(dtype), "device": args.device,
            "model_dir": str(local_dir), "save_dir": str(sample_dir),
            "batch_size": B,
        }
        with open(sample_dir / "metadata.json", "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)

        # æ­¥æ•°æ˜ å°„ï¼ˆå¯å‘å¼ï¼‰
        call_map = []
        for call_idx in range(len(dit_outputs_batched)):
            step_idx = call_idx // approx_calls_per_step
            is_cfg_negative = (call_idx % approx_calls_per_step == 0 and approx_calls_per_step == 2)
            call_map.append({"call_idx": call_idx, "approx_step": int(step_idx), "is_cfg_negative": int(is_cfg_negative)})
        with open(sample_dir / "step_map.json", "w", encoding="utf-8") as f:
            json.dump({"calls": call_map}, f, ensure_ascii=False, indent=2)

    print("\nâœ… å®Œæˆã€‚æ‰€æœ‰ç»“æœä½äºï¼š", session_dir)

if __name__ == "__main__":
    main()

